{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet网络\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差单元\n",
    "# 两个3*3的卷积层，每个卷积层后面跟一个批量归一化层和ReLu激活函数\n",
    "# 如果想要改变输入X的通道数，这样可以和卷积层的输出相加\n",
    "\n",
    "class Residual(tf.keras.Model):\n",
    "    def __init__(self, channels, use_1x1conv=False, strides=1, **kwargs):\n",
    "        super(Residual, self).__init__(**kwargs)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(channels, kernel_size=3, strides=strides, padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(channels, kernel_size=3, padding='same') # 这个地方的strides应该不变还为1\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = tf.keras.layers.Conv2D(channels, kernel_size=1, strides=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, X):\n",
    "        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        return tf.keras.activations.relu(Y + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 6, 6, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(3)\n",
    "#tensorflow input shpe     (n_images, x_shape, y_shape, channels).\n",
    "#mxnet.gluon.nn.conv_layers    (batch_size, in_channels, height, width) \n",
    "X = tf.random.uniform((4, 6, 6 , 3))\n",
    "blk(X).shape#TensorShape([4, 6, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 3, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = Residual(6, use_1x1conv=True, strides=2)\n",
    "blk(X).shape\n",
    "#TensorShape([4, 3, 3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差模块 \n",
    "# 第一个模块的通道数同输入通道数一致。由于之前已经使用了步幅为2的最大池化层，所以无须减小高和宽。\n",
    "# 之后的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。\n",
    "\n",
    "class ResnetBlock(tf.keras.Model):\n",
    "    def __init__(self, channels, num_residuals, first_block=False, **kwargs):\n",
    "        super(ResnetBlock, self).__init__(**kwargs)\n",
    "        self.ListLayers = []\n",
    "        for i in range(num_residuals):\n",
    "            if (i==0) and (not first_block):\n",
    "                # 每个残差模块中需要利用use_1x1conv将输入的通道数进行转换，这样才能和残差映射相加\n",
    "                self.ListLayers.append(Residual(channels, use_1x1conv=True, strides=2)) \n",
    "            else:\n",
    "                self.ListLayers.append(Residual(channels))\n",
    "    \n",
    "    def call(self, X):\n",
    "        for layer in self.ListLayers.layers:\n",
    "            X = layer(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet模型\n",
    "# 残差模型的前两层和GoogLeNet一样\n",
    "# 通道数64，7*7 步幅为2的卷积层 + 批量归一化层\n",
    "# 3*3步幅为2的最大池化层\n",
    "# 4个残差模块\n",
    "# 全局平均池化层\n",
    "# 全连接输出层 tf.keras.activaitons.softmax\n",
    "\n",
    "class ResNet(tf.keras.Model):\n",
    "    def __init__(self, num_blocks, **kwargs):\n",
    "        super(ResNet, self).__init__(**kwargs)\n",
    "        self.conv = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.Activation('relu')\n",
    "        self.mp = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')\n",
    "        self.resnet_block1 = ResnetBlock(64, num_blocks[0], first_block=True)\n",
    "        self.resnet_block2 = ResnetBlock(128, num_blocks[1])\n",
    "        self.resnet_block3 = ResnetBlock(256, num_blocks[2])\n",
    "        self.resnet_block4 = ResnetBlock(512, num_blocks[3])\n",
    "        self.gap = tf.keras.layers.GlobalAvgPool2D()\n",
    "        self.fc = tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "    \n",
    "    def call(self, X):\n",
    "        X = self.conv(X)\n",
    "        X = self.bn(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.mp(X)\n",
    "        X = self.resnet_block1(X)\n",
    "        X = self.resnet_block2(X)\n",
    "        X = self.resnet_block3(X)\n",
    "        X = self.resnet_block4(X)\n",
    "        X = self.gap(X)\n",
    "        X = self.fc(X)\n",
    "        return X\n",
    "\n",
    "ResNet = ResNet([2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_5 output_shape:\t (1, 112, 112, 64)\n",
      "batch_normalization_4 output_shape:\t (1, 112, 112, 64)\n",
      "activation output_shape:\t (1, 112, 112, 64)\n",
      "max_pooling2d output_shape:\t (1, 56, 56, 64)\n",
      "resnet_block output_shape:\t (1, 56, 56, 64)\n",
      "resnet_block_1 output_shape:\t (1, 28, 28, 128)\n",
      "resnet_block_2 output_shape:\t (1, 14, 14, 256)\n",
      "resnet_block_3 output_shape:\t (1, 7, 7, 512)\n",
      "global_average_pooling2d output_shape:\t (1, 512)\n",
      "dense output_shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 224, 224, 1))\n",
    "for layer in ResNet.layers:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output_shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 18s 21ms/step - loss: 0.6854 - accuracy: 0.7715 - val_loss: 0.4501 - val_accuracy: 0.8334\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 0.3411 - accuracy: 0.8725 - val_loss: 0.3522 - val_accuracy: 0.8687\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 0.2821 - accuracy: 0.8961 - val_loss: 0.3574 - val_accuracy: 0.8698\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 0.2658 - accuracy: 0.9015 - val_loss: 0.3474 - val_accuracy: 0.8724\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 15s 20ms/step - loss: 0.2408 - accuracy: 0.9120 - val_loss: 0.2801 - val_accuracy: 0.9009\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_train = X_train.reshape((60000, 28, 28, 1)).astype(\"float\") / 255.0\n",
    "X_test = X_test.reshape((10000, 28, 28, 1)).astype(np.float32) / 255.0\n",
    "\n",
    "ResNet.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "history = ResNet.fit(X_train, Y_train,batch_size=64, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc25781e280>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
