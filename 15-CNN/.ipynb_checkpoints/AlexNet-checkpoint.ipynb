{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于tensorflow的AlexNet的实现\n",
    "# 设置GPU进行训练\n",
    "# 模型编译（总共有11层，5层卷积，3层池化，3层全连接\n",
    "#     1. 卷积层（filters=96， kernel_size=11，strides=4, activation='ReLu'\n",
    "#     2. 最大池化层（pool_size=3, stirdes=2)\n",
    "#     3. 卷积层(filters=256, kernel_size=5, padding='same', activation='ReLu')\n",
    "#     4. 最大池化层(pool_size=3, strides=2)\n",
    "#     5. 卷积层(filters=384, kernel_size=3, padding='same', activation='ReLu')\n",
    "#     6. 卷积层(filters=384, kernel_size=3, padding='same', activation='ReLu')\n",
    "#     7. 卷积层(filters=256, kernel_size=3, padding='same', activation='ReLu')\n",
    "#     8. 最大池化层（pool_size=3, stirdes=2)\n",
    "#     9. 摊平\n",
    "#     10. 全连接层(units=4096, activation='ReLu')\n",
    "#     11. dropout(0.5)\n",
    "#     12. 全连接层(units=4096, activation='ReLu')\n",
    "#     13. dropout(0.5)\n",
    "#     14. 全连接层(units=10, activation='sigmoid')\n",
    "# 数据处理\n",
    "#     直接用ImageNet训练时间太久了，将fashion_mnist扩充 \n",
    "#     利用tf.image.resize_with_pad(image, target_height, target_width, 其他默认参数就好)\n",
    "# 优化器 tf.keras.optimizes.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "# 模型编译，loss=sparse_categorical_crossentropy\n",
    "# 模型训练 net.fit(X,Y, validation_split=0.1)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用GPU训练\n",
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet 模型\n",
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=10, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "class DataLoad():\n",
    "    def __init__(self):\n",
    "        (self.train_images, self.train_labels), (self.test_images, self.test_labels) = fashion_mnist.load_data()\n",
    "        self.train_images = np.expand_dims(self.train_images.astype(np.float32) / 255.0, axis=-1)\n",
    "        self.test_images = np.expand_dims(self.test_images.astype(np.float32) / 255.0, axis=-1)\n",
    "        self.train_labels = self.train_labels.astype(np.int32)\n",
    "        self.test_labels = self.test_labels.astype(np.int32)\n",
    "        self.train_num, self.test_num = self.train_images.shape[0], self.test_images.shape[0]\n",
    "    \n",
    "    def get_train_batch(self, batch_size):\n",
    "        index = np.random.randint(0, self.train_num, batch_size)\n",
    "        train_batch = tf.image.resize_with_pad(self.train_images[index], 244, 244)\n",
    "        return train_batch, self.train_labels[index]\n",
    "    \n",
    "    def get_test_batch(self, batch_size):\n",
    "        index = np.random.randint(0, self.test_num, batch_size)\n",
    "        test_batch = tf.image.resize_with_pad(self.test_images[index], 244, 244)\n",
    "        return test_batch, self.test_labels[index]\n",
    "\n",
    "batch_size = 2000\n",
    "data_load = DataLoad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 7s 55ms/step - loss: 2.2978 - accuracy: 0.1284 - val_loss: 2.2695 - val_accuracy: 0.2800\n",
      "57/57 [==============================] - 2s 41ms/step - loss: 2.1540 - accuracy: 0.2356 - val_loss: 2.7955 - val_accuracy: 0.1100\n",
      "57/57 [==============================] - 2s 41ms/step - loss: 1.5974 - accuracy: 0.4094 - val_loss: 1.5347 - val_accuracy: 0.3850\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 1.2737 - accuracy: 0.5239 - val_loss: 1.4812 - val_accuracy: 0.4250\n",
      "57/57 [==============================] - 2s 41ms/step - loss: 1.1016 - accuracy: 0.5844 - val_loss: 0.8805 - val_accuracy: 0.6200\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.9639 - accuracy: 0.6411 - val_loss: 1.1663 - val_accuracy: 0.5450\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.9062 - accuracy: 0.6561 - val_loss: 1.0763 - val_accuracy: 0.7000\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.8134 - accuracy: 0.7022 - val_loss: 0.8030 - val_accuracy: 0.7100\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.7990 - accuracy: 0.6917 - val_loss: 1.1999 - val_accuracy: 0.6000\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.7662 - accuracy: 0.7144 - val_loss: 0.7752 - val_accuracy: 0.7500\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.7722 - accuracy: 0.7106 - val_loss: 0.8356 - val_accuracy: 0.7200\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.6603 - accuracy: 0.7567 - val_loss: 0.6260 - val_accuracy: 0.7400\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.6653 - accuracy: 0.7472 - val_loss: 0.5506 - val_accuracy: 0.7800\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.6291 - accuracy: 0.7594 - val_loss: 1.1267 - val_accuracy: 0.6150\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.6563 - accuracy: 0.7506 - val_loss: 0.6143 - val_accuracy: 0.7600\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.6301 - accuracy: 0.7572 - val_loss: 0.5221 - val_accuracy: 0.8150\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5760 - accuracy: 0.7828 - val_loss: 0.5541 - val_accuracy: 0.7950\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5768 - accuracy: 0.7833 - val_loss: 0.6318 - val_accuracy: 0.7750\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5934 - accuracy: 0.7706 - val_loss: 0.5407 - val_accuracy: 0.8050\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.5759 - accuracy: 0.7794 - val_loss: 0.6573 - val_accuracy: 0.7650\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5559 - accuracy: 0.7906 - val_loss: 0.5569 - val_accuracy: 0.7850\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5533 - accuracy: 0.7933 - val_loss: 0.4823 - val_accuracy: 0.8100\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5225 - accuracy: 0.8061 - val_loss: 0.3945 - val_accuracy: 0.8550\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.5454 - accuracy: 0.7989 - val_loss: 0.6134 - val_accuracy: 0.7800\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5373 - accuracy: 0.8044 - val_loss: 0.6118 - val_accuracy: 0.7850\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5455 - accuracy: 0.7967 - val_loss: 0.5970 - val_accuracy: 0.7750\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5138 - accuracy: 0.8156 - val_loss: 0.4874 - val_accuracy: 0.8100\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.5012 - accuracy: 0.8122 - val_loss: 0.5147 - val_accuracy: 0.8100\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5108 - accuracy: 0.8156 - val_loss: 0.4174 - val_accuracy: 0.8500\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4911 - accuracy: 0.8194 - val_loss: 0.4300 - val_accuracy: 0.8250\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5093 - accuracy: 0.8128 - val_loss: 0.5732 - val_accuracy: 0.8050\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.4439 - accuracy: 0.8472 - val_loss: 0.5075 - val_accuracy: 0.7650\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4618 - accuracy: 0.8283 - val_loss: 0.6662 - val_accuracy: 0.7400\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4750 - accuracy: 0.8283 - val_loss: 0.3942 - val_accuracy: 0.8550\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4736 - accuracy: 0.8178 - val_loss: 0.3645 - val_accuracy: 0.8700\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.4488 - accuracy: 0.8294 - val_loss: 0.3310 - val_accuracy: 0.8700\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4416 - accuracy: 0.8356 - val_loss: 0.3111 - val_accuracy: 0.8850\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4501 - accuracy: 0.8256 - val_loss: 0.4662 - val_accuracy: 0.8550\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4348 - accuracy: 0.8372 - val_loss: 0.3196 - val_accuracy: 0.9000\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.4676 - accuracy: 0.8278 - val_loss: 0.7191 - val_accuracy: 0.7350\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.4513 - accuracy: 0.8328 - val_loss: 0.4828 - val_accuracy: 0.8150\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4252 - accuracy: 0.8422 - val_loss: 0.5072 - val_accuracy: 0.8200\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4009 - accuracy: 0.8633 - val_loss: 0.5603 - val_accuracy: 0.7800\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.4434 - accuracy: 0.8328 - val_loss: 0.3311 - val_accuracy: 0.8850\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4407 - accuracy: 0.8461 - val_loss: 0.4619 - val_accuracy: 0.8300\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4458 - accuracy: 0.8450 - val_loss: 0.3834 - val_accuracy: 0.8800\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4279 - accuracy: 0.8394 - val_loss: 0.3205 - val_accuracy: 0.9050\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.4302 - accuracy: 0.8417 - val_loss: 0.3014 - val_accuracy: 0.8800\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3932 - accuracy: 0.8522 - val_loss: 0.3765 - val_accuracy: 0.8500\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3837 - accuracy: 0.8633 - val_loss: 0.4119 - val_accuracy: 0.8550\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4483 - accuracy: 0.8344 - val_loss: 0.3891 - val_accuracy: 0.8700\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.3937 - accuracy: 0.8578 - val_loss: 0.3401 - val_accuracy: 0.9000\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4178 - accuracy: 0.8517 - val_loss: 0.3502 - val_accuracy: 0.8800\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3785 - accuracy: 0.8522 - val_loss: 0.3621 - val_accuracy: 0.8900\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3824 - accuracy: 0.8606 - val_loss: 0.3832 - val_accuracy: 0.8400\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.3757 - accuracy: 0.8600 - val_loss: 0.4220 - val_accuracy: 0.8450\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3877 - accuracy: 0.8561 - val_loss: 0.5577 - val_accuracy: 0.8250\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4362 - accuracy: 0.8494 - val_loss: 0.3073 - val_accuracy: 0.9100\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3914 - accuracy: 0.8583 - val_loss: 0.5706 - val_accuracy: 0.8100\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.3884 - accuracy: 0.8506 - val_loss: 0.3743 - val_accuracy: 0.8750\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3777 - accuracy: 0.8656 - val_loss: 0.4046 - val_accuracy: 0.8650\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3696 - accuracy: 0.8650 - val_loss: 0.4398 - val_accuracy: 0.8600\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3830 - accuracy: 0.8600 - val_loss: 0.3396 - val_accuracy: 0.8550\n",
      "57/57 [==============================] - 3s 44ms/step - loss: 0.3668 - accuracy: 0.8689 - val_loss: 0.3112 - val_accuracy: 0.9000\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3543 - accuracy: 0.8661 - val_loss: 0.3338 - val_accuracy: 0.8750\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3858 - accuracy: 0.8628 - val_loss: 0.4075 - val_accuracy: 0.8500\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3824 - accuracy: 0.8439 - val_loss: 0.3346 - val_accuracy: 0.8800\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.3575 - accuracy: 0.8639 - val_loss: 0.3202 - val_accuracy: 0.8700\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3894 - accuracy: 0.8622 - val_loss: 0.4080 - val_accuracy: 0.8550\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3855 - accuracy: 0.8611 - val_loss: 0.2942 - val_accuracy: 0.8900\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3488 - accuracy: 0.8683 - val_loss: 0.4353 - val_accuracy: 0.8400\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.4021 - accuracy: 0.8611 - val_loss: 0.3667 - val_accuracy: 0.8650\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3782 - accuracy: 0.8578 - val_loss: 0.3332 - val_accuracy: 0.8850\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3704 - accuracy: 0.8650 - val_loss: 0.2872 - val_accuracy: 0.9150\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3173 - accuracy: 0.8889 - val_loss: 0.4775 - val_accuracy: 0.8100\n",
      "57/57 [==============================] - 2s 44ms/step - loss: 0.3452 - accuracy: 0.8661 - val_loss: 0.4290 - val_accuracy: 0.8450\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3622 - accuracy: 0.8644 - val_loss: 0.3904 - val_accuracy: 0.8350\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3613 - accuracy: 0.8678 - val_loss: 0.4451 - val_accuracy: 0.8200\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3858 - accuracy: 0.8572 - val_loss: 0.3520 - val_accuracy: 0.8950\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3483 - accuracy: 0.8772 - val_loss: 0.2584 - val_accuracy: 0.9100\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3815 - accuracy: 0.8544 - val_loss: 0.3887 - val_accuracy: 0.8700\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3620 - accuracy: 0.8672 - val_loss: 0.3578 - val_accuracy: 0.8550\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3540 - accuracy: 0.8756 - val_loss: 0.3245 - val_accuracy: 0.8800\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3432 - accuracy: 0.8794 - val_loss: 0.3182 - val_accuracy: 0.8950\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3306 - accuracy: 0.8772 - val_loss: 0.4140 - val_accuracy: 0.8250\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3312 - accuracy: 0.8761 - val_loss: 0.3567 - val_accuracy: 0.8700\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3799 - accuracy: 0.8561 - val_loss: 0.3882 - val_accuracy: 0.8450\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3183 - accuracy: 0.8811 - val_loss: 0.2550 - val_accuracy: 0.9050\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3404 - accuracy: 0.8744 - val_loss: 0.2955 - val_accuracy: 0.9250\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3377 - accuracy: 0.8722 - val_loss: 0.4100 - val_accuracy: 0.8600\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3336 - accuracy: 0.8794 - val_loss: 0.1755 - val_accuracy: 0.9500\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3237 - accuracy: 0.8733 - val_loss: 0.2666 - val_accuracy: 0.9150\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3487 - accuracy: 0.8689 - val_loss: 0.3120 - val_accuracy: 0.8750\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3119 - accuracy: 0.8822 - val_loss: 0.3523 - val_accuracy: 0.8600\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3411 - accuracy: 0.8778 - val_loss: 0.3726 - val_accuracy: 0.8400\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3358 - accuracy: 0.8689 - val_loss: 0.3284 - val_accuracy: 0.8900\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.3472 - accuracy: 0.8789 - val_loss: 0.4284 - val_accuracy: 0.8400\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3245 - accuracy: 0.8806 - val_loss: 0.4323 - val_accuracy: 0.8250\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3463 - accuracy: 0.8739 - val_loss: 0.4084 - val_accuracy: 0.8600\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3159 - accuracy: 0.8844 - val_loss: 0.3896 - val_accuracy: 0.8650\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3047 - accuracy: 0.8911 - val_loss: 0.2323 - val_accuracy: 0.9300\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3272 - accuracy: 0.8906 - val_loss: 0.3206 - val_accuracy: 0.8600\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3123 - accuracy: 0.8894 - val_loss: 0.2221 - val_accuracy: 0.9250\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3228 - accuracy: 0.8761 - val_loss: 0.3161 - val_accuracy: 0.8800\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3255 - accuracy: 0.8800 - val_loss: 0.2824 - val_accuracy: 0.9000\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3157 - accuracy: 0.8794 - val_loss: 0.2634 - val_accuracy: 0.8850\n",
      "57/57 [==============================] - 2s 42ms/step - loss: 0.3429 - accuracy: 0.8767 - val_loss: 0.2563 - val_accuracy: 0.9350\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3478 - accuracy: 0.8756 - val_loss: 0.3057 - val_accuracy: 0.8800\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2822 - accuracy: 0.8989 - val_loss: 0.2614 - val_accuracy: 0.9100\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3451 - accuracy: 0.8872 - val_loss: 0.2305 - val_accuracy: 0.9250\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3294 - accuracy: 0.8739 - val_loss: 0.3452 - val_accuracy: 0.8900\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3242 - accuracy: 0.8822 - val_loss: 0.2810 - val_accuracy: 0.8950\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3336 - accuracy: 0.8833 - val_loss: 0.2728 - val_accuracy: 0.9100\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3328 - accuracy: 0.8783 - val_loss: 0.2943 - val_accuracy: 0.8850\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2864 - accuracy: 0.8906 - val_loss: 0.2707 - val_accuracy: 0.9050\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2000,244,244,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ResizeBilinear]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-df9cf14e6241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m            \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m            metrics=['accuracy'])\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_AlexNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-df9cf14e6241>\u001b[0m in \u001b[0;36mtrain_AlexNet\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnum_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_num\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7d79db9274b7>\u001b[0m in \u001b[0;36mget_train_batch\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_train_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_with_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m244\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m244\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_image_with_pad_v2\u001b[0;34m(image, target_height, target_width, method, antialias)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresize_images_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m   return _resize_image_with_pad_common(image, target_height, target_width,\n\u001b[0m\u001b[1;32m   1806\u001b[0m                                        _resize_fn)\n\u001b[1;32m   1807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_image_with_pad_common\u001b[0;34m(image, target_height, target_width, resize_fn)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;31m# Resize first, then pad to meet requested dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m     \u001b[0mresized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresized_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresized_width\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m     padded = pad_to_bounding_box(resized, p_height, p_width, target_height,\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_fn\u001b[0;34m(im, new_size)\u001b[0m\n\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_resize_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1803\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresize_images_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m   return _resize_image_with_pad_common(image, target_height, target_width,\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_images_v2\u001b[0;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[1;32m   1639\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resize method is not implemented: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m   return _resize_images_common(\n\u001b[0m\u001b[1;32m   1642\u001b[0m       \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m       \u001b[0mresize_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresizer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# NOTE(mrry): The shape functions for the resize ops cannot unpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_fn\u001b[0;34m(images_t, new_size)\u001b[0m\n\u001b[1;32m   1621\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresize_with_scale_and_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'triangle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         return gen_image_ops.resize_bilinear(\n\u001b[0m\u001b[1;32m   1624\u001b[0m             images_t, new_size, half_pixel_centers=True)\n\u001b[1;32m   1625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResizeMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEAREST_NEIGHBOR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mresize_bilinear\u001b[0;34m(images, size, align_corners, half_pixel_centers, name)\u001b[0m\n\u001b[1;32m   3663\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3664\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3665\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3666\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3667\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2000,244,244,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ResizeBilinear]"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "def train_AlexNet():\n",
    "    epochs = 5\n",
    "    for _ in range(epochs):\n",
    "        num_iter = data_load.train_num // batch_size\n",
    "        for t in range(num_iter):\n",
    "            X_train, Y_train = data_load.get_train_batch(batch_size)\n",
    "            net.fit(X_train, Y_train)\n",
    "            if t % 20 == 0:\n",
    "                net.save_weights('alexnet_weights.h5')\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "net.compile(optimizer=optimizer,\n",
    "           loss= 'sparse_categorical_crossentropy',\n",
    "           metrics=['accuracy'])\n",
    "train_AlexNet()\n",
    "# 显存不够算不完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2000,244,244,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ResizeBilinear]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ca65ebdbea8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alexnet_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7d79db9274b7>\u001b[0m in \u001b[0;36mget_test_batch\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_test_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtest_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_with_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m244\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m244\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_image_with_pad_v2\u001b[0;34m(image, target_height, target_width, method, antialias)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresize_images_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m   return _resize_image_with_pad_common(image, target_height, target_width,\n\u001b[0m\u001b[1;32m   1806\u001b[0m                                        _resize_fn)\n\u001b[1;32m   1807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_image_with_pad_common\u001b[0;34m(image, target_height, target_width, resize_fn)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;31m# Resize first, then pad to meet requested dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m     \u001b[0mresized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresized_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresized_width\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m     padded = pad_to_bounding_box(resized, p_height, p_width, target_height,\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_fn\u001b[0;34m(im, new_size)\u001b[0m\n\u001b[1;32m   1801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_resize_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1803\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresize_images_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m   return _resize_image_with_pad_common(image, target_height, target_width,\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_images_v2\u001b[0;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[1;32m   1639\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resize method is not implemented: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m   return _resize_images_common(\n\u001b[0m\u001b[1;32m   1642\u001b[0m       \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m       \u001b[0mresize_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresizer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# NOTE(mrry): The shape functions for the resize ops cannot unpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_fn\u001b[0;34m(images_t, new_size)\u001b[0m\n\u001b[1;32m   1621\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresize_with_scale_and_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'triangle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         return gen_image_ops.resize_bilinear(\n\u001b[0m\u001b[1;32m   1624\u001b[0m             images_t, new_size, half_pixel_centers=True)\n\u001b[1;32m   1625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResizeMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEAREST_NEIGHBOR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mresize_bilinear\u001b[0;34m(images, size, align_corners, half_pixel_centers, name)\u001b[0m\n\u001b[1;32m   3663\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3664\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3665\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3666\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3667\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf2/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2000,244,244,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ResizeBilinear]"
     ]
    }
   ],
   "source": [
    "# 显存不够\n",
    "net.load_weights('alexnet_weights.h5')\n",
    "test_images, test_labels = data_load.get_test_batch(batch_size)\n",
    "net.evaluate(test_images, test_labels, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
