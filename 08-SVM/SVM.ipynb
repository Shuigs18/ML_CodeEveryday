{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "        1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "       -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "        1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "       -1.,  1., -1.,  1.,  1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 数据准备阶段\n",
    "# 加载数据进行测试\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "df['label'] = iris.target\n",
    "df.columns = [\n",
    "     'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "]\n",
    "df[df == 0] = -1\n",
    "data = np.array(df.iloc[:100, [0, 1, -1]]) # 取前两类\n",
    "X, y = data[:, :2], data[:, -1]  # X只取两个维度\n",
    "\n",
    "## 对数据进行随机化\n",
    "def shuffle(X, Y):\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "    return X[randomize], Y[randomize]\n",
    "\n",
    "data_X, data_y = shuffle(X, y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_X, data_y, test_size = 0.3)\n",
    "\n",
    "plt.scatter(X[:50, 0], X[:50, 1], label = '0')\n",
    "plt.scatter(X[50:, 0], X[50:, 1], label = '1')\n",
    "plt.legend()\n",
    "Y_train # 是一个array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM 类\n",
    "    # 相关参数初始化\n",
    "    # func2. 计算核函数 返回高斯核矩阵（即所有变量间的核函数）\n",
    "    # func3. 判断是否满足KKT条件\n",
    "    # func4. 计算g（xi）= wx+b\n",
    "    # func5. 计算Ei\n",
    "    # func6. 获得第二个变量 alpha 2\n",
    "    # func7. 训练函数\n",
    "    # func8. 单独计算两个变量之间的核函数 我觉得不需要\n",
    "    # func8. 预测函数\n",
    "    # func9. 测试函数\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, X_train, Y_train, sigma = 10, C = 200, toler = 0.001, iter_times = 300):\n",
    "        '''\n",
    "        参数初始化：\n",
    "        X_train: 训练数据集 numpy array 格式\n",
    "        Y_trian: 训练标签集 numpy array 格式\n",
    "        sigma: 高斯核中的参数\n",
    "        C: 惩罚参数\n",
    "        toler: 松弛变量\n",
    "        '''\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.m, self.n = np.shape(X_train)   # m 为训练集中的数据个数， n为数据的维度\n",
    "        self.sigma = sigma\n",
    "        self.C = C\n",
    "        self.toler = toler\n",
    "        self.iter_times = iter_times\n",
    "        \n",
    "        self.k = self.calcKernel()                # 核函数初始化\n",
    "        self.b = 0.\n",
    "        self.alpha = np.zeros_like(Y_train)          # 目标函数的参数，要学习的参数\n",
    "        self.Ei = np.zeros_like(Y_train)               # Ei g(xi) 与 yi的差值\n",
    "        self.supportIndex = []                   # 用来存储支持向量\n",
    "    \n",
    "    def calcKernel(self): \n",
    "        '''\n",
    "        计算高斯核函数，并返回高斯核函数矩阵\n",
    "        '''\n",
    "        kernel = np.empty([self.m, self.m], dtype = float)  # 初始化高斯核矩阵\n",
    "        \n",
    "        # 该矩阵是对称的，所以只需要计算一半就行了\n",
    "        for i in range(self.m):\n",
    "            for j in range(i, self.m):\n",
    "                kernel[i][j] = np.exp( - (np.linalg.norm(self.X_train[i] - self.X_train[j], ord=2) ** 2) / (2 * self.sigma**2) )\n",
    "                kernel[j][i] = kernel[i][j]\n",
    "        \n",
    "        return kernel\n",
    "    \n",
    "    def isSatisfyKTT(self, i):\n",
    "        '''\n",
    "        查看第下标为i的alpha是否满足KTT条件\n",
    "        '''\n",
    "        gxi = self.calc_gxi(i)\n",
    "        yi = self.Y_train[i]\n",
    "        \n",
    "        if (math.fabs(self.alpha[i]) < self.toler) and (yi * gxi  >= 1):\n",
    "            return True\n",
    "        elif (self.alpha[i] > -self.toler and self.alpha[i] < self.C + self.toler) and \\\n",
    "             (math.fabs(gxi * yi - 1) < self.toler):\n",
    "            return True\n",
    "        elif (math.fabs(self.alpha[i] - self.C) < self.toler) and (yi * gxi <= 1):\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def calc_gxi(self, i):\n",
    "        return sum(self.alpha * self.Y_train * self.k[i]) + self.b\n",
    "        # 但是怎么算有一个缺点，没有考虑alpha = 0 的x不需要算，也就是如果要提高计算效率，应该只考虑支持向量，也就是alpha ！= 0 的点\n",
    "    \n",
    "    def calcEi(self, i):\n",
    "        gxi = self.calc_gxi(i)\n",
    "        return gxi - self.Y_train[i]\n",
    "    \n",
    "    def getAlpha(self, E1, i):\n",
    "        '''\n",
    "        E1: 第一个alpha的 E1\n",
    "        i: 第一个alpha的下标\n",
    "        return: 第二个alpha， 第二个alpha的下标\n",
    "        '''\n",
    "        # 初始化\n",
    "        E2 = 0\n",
    "        # 初始化\n",
    "        maxE1_E2 = -1  \n",
    "        # 初始化 第二个变量的下标\n",
    "        maxIndex = -1  \n",
    "        \n",
    "        nozeroEi = [i for i, Ei in enumerate(self.Ei) if Ei != 0]\n",
    "        for j in np.arange(len(nozeroEi)):\n",
    "            E2_temp = self.calcEi(j)\n",
    "            if math.fabs(E2_temp - E1) > maxE1_E2:\n",
    "                maxE1_E2 = math.fabs(E2_temp - E1)\n",
    "                E2 = E2_temp\n",
    "                maxIndex = j\n",
    "        if maxIndex == -1: # 对应刚开始的时候，如果列表中没有非0元素了\n",
    "            maxIndex = i\n",
    "            while (maxIndex == i):\n",
    "                maxIndex = int(random.uniform(0, self.m))\n",
    "            E2 = self.calcEi(maxIndex)\n",
    "        \n",
    "        return E2, maxIndex\n",
    "    \n",
    "    def train(self):\n",
    "        iterStep = 0; parameterChange = 1\n",
    "        # iterStep迭代次数\n",
    "        # parameterChange 参数改变次数，parameterChange==0表示上次迭代中参数没有发生变化，如果参数没有发生变化则训练终止\n",
    "        while (iterStep < self.iter_times) and (parameterChange > 0):\n",
    "            iterStep += 1\n",
    "            parameterChange = 0\n",
    "            \n",
    "            # 大循环用于寻找第一个变量\n",
    "            for i in range(self.m):\n",
    "                # 如果不满足KKT条件\n",
    "                if self.isSatisfyKTT(i) == False: # 这里寻找第一个变量的方法是直接遍历，而非量化违反KTT条件，去寻找最严重的那一个\n",
    "                    E1 = self.calcEi(i)\n",
    "                    E2, j = self.getAlpha(E1, i)\n",
    "                \n",
    "                    y1 = self.Y_train[i]\n",
    "                    y2 = self.Y_train[j]\n",
    "                    \n",
    "                    oldAlpha1 = self.alpha[i]\n",
    "                    oldAlpha2 = self.alpha[j]\n",
    "                    \n",
    "                    if y1 != y2:\n",
    "                        L = max(0., oldAlpha2 - oldAlpha1)\n",
    "                        H = min(self.C, self.C + oldAlpha2 - oldAlpha1)\n",
    "                    else:\n",
    "                        L = max(0., oldAlpha2 + oldAlpha1 - self.C)\n",
    "                        H = min(self.C, oldAlpha2 + oldAlpha1)\n",
    "                    \n",
    "                    # 如果L==H，说明该变量无法在优化，直接跳到下一个循环\n",
    "                    if L == H:  continue\n",
    "                    \n",
    "                    K11 = self.k[i][i]\n",
    "                    K22 = self.k[j][j]\n",
    "                    K12 = self.k[i][j]\n",
    "                    K21 = self.k[j][i]\n",
    "                    \n",
    "                    # 计算未经剪辑的alpha2\n",
    "                    newAlpha2 = oldAlpha2 + y2 * (E1 - E2) / (K11 + K22 - 2 * K12)\n",
    "                    \n",
    "                    # 对alpha2进行剪辑\n",
    "                    if newAlpha2 > H:  newAlpha2 = H\n",
    "                    if newAlpha2 < L:  newAlpha2 = L\n",
    "                        \n",
    "                    # 计算alpha1\n",
    "                    newAlpha1 = oldAlpha1 + y1 * y2 * (oldAlpha2 - newAlpha2)\n",
    "                    \n",
    "                    # 在完成两个alpha的更新后，需要更新参数b\n",
    "                    newb1 = - E1 - y1 * K11 * (newAlpha1 - oldAlpha1) - \\\n",
    "                            y2 * K21 * (newAlpha2 - oldAlpha2) + self.b\n",
    "                    newb2 = - E2 - y1 * K12 * (newAlpha1 - oldAlpha1) - \\\n",
    "                            y2 * K22 * (newAlpha2 - oldAlpha2) + self.b\n",
    "                    \n",
    "                    if (newAlpha1 > 0) and (newAlpha1 < self.C):\n",
    "                        newb = newb1\n",
    "                    elif (newAlpha2 > 0) and (newAlpha2 < self.C):\n",
    "                        newb = newb2\n",
    "                    else:\n",
    "                        newb = (newb1 + newb2) / 2\n",
    "                    \n",
    "                    # 更新完 alpha 和 b之后，先存储，方便之后更新E\n",
    "                    self.alpha[i] = newAlpha1\n",
    "                    self.alpha[j] = newAlpha2\n",
    "                    self.b = newb\n",
    "                    # 除了要更新b之外，还需要更新对应的Ei的值，并将它们保存在列表中\n",
    "                    \n",
    "                    self.Ei[i] = self.calcEi(i)\n",
    "                    self.Ei[j] = self.calcEi(j)\n",
    "                    \n",
    "                    if (math.fabs(oldAlpha2 - newAlpha2) >= 0.00001):\n",
    "                        parameterChange += 1\n",
    "        # 保存支持向量，当数据量很大时可以用来优化\n",
    "        for i in range(self.m):\n",
    "            if self.alpha[i] > 0:\n",
    "                self.supportIndex.append(i)\n",
    "                \n",
    "    def calcSingleKernel(self, x1, x2):\n",
    "        '''\n",
    "        x1: array\n",
    "        x2: array\n",
    "        '''\n",
    "        result = np.exp( - (np.linalg.norm(x1 - x2, ord=2) ** 2) / (self.sigma ** 2) )\n",
    "        return result\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        X_test: 预测数据集，格式numpy array\n",
    "        return 预测结果 numpy array 数组\n",
    "        '''\n",
    "        result = np.empty([len(X_test)], dtype = float)\n",
    "        K_x_xi = np.empty([self.m], dtype=float)\n",
    "        for j in range(len(X_test)):\n",
    "            for i in range(self.m):\n",
    "                K_x_xi[i] = self.calcSingleKernel(X_test[j], self.X_train[i])\n",
    "            result[j] = np.sum(self.alpha * self.Y_train * K_x_xi) + self.b\n",
    "        \n",
    "        return np.sign(result)\n",
    "    \n",
    "    def score(self, X_test, Y_test):\n",
    "        prediction = self.predict(X_test)\n",
    "        right_count = 0\n",
    "        for i in range(len(Y_test)):\n",
    "            if prediction[i] == Y_test[i]:\n",
    "                right_count += 1\n",
    "                \n",
    "        return right_count / len(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
       "       -1.,  1.,  1., -1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = svm.predict(X_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.svm.SVC\n",
    "\n",
    "*(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False,tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None,random_state=None)*\n",
    "\n",
    "参数：\n",
    "\n",
    "- C：C-SVC的惩罚参数C?默认值是1.0\n",
    "\n",
    "C越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。\n",
    "\n",
    "- kernel ：核函数，默认是rbf，可以是‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ \n",
    "    \n",
    "    – 线性：u'v\n",
    "    \n",
    "    – 多项式：(gamma*u'*v + coef0)^degree\n",
    "\n",
    "    – RBF函数：exp(-gamma|u-v|^2)\n",
    "\n",
    "    – sigmoid：tanh(gamma*u'*v + coef0)\n",
    "\n",
    "\n",
    "- degree ：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略。\n",
    "\n",
    "\n",
    "- gamma ： ‘rbf’,‘poly’ 和‘sigmoid’的核函数参数。默认是’auto’，则会选择1/n_features\n",
    "\n",
    "\n",
    "- coef0 ：核函数的常数项。对于‘poly’和 ‘sigmoid’有用。\n",
    "\n",
    "\n",
    "- probability ：是否采用概率估计？.默认为False\n",
    "\n",
    "\n",
    "- shrinking ：是否采用shrinking heuristic方法，默认为true\n",
    "\n",
    "\n",
    "- tol ：停止训练的误差值大小，默认为1e-3\n",
    "\n",
    "\n",
    "- cache_size ：核函数cache缓存大小，默认为200\n",
    "\n",
    "\n",
    "- class_weight ：类别的权重，字典形式传递。设置第几类的参数C为weight*C(C-SVC中的C)\n",
    "\n",
    "\n",
    "- verbose ：允许冗余输出？\n",
    "\n",
    "\n",
    "- max_iter ：最大迭代次数。-1为无限制。\n",
    "\n",
    "\n",
    "- decision_function_shape ：‘ovo’, ‘ovr’ or None, default=None3\n",
    "\n",
    "\n",
    "- random_state ：数据洗牌时的种子值，int值\n",
    "\n",
    "\n",
    "主要调节的参数有：C、kernel、degree、gamma、coef0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn 实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
